{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666e82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Lambda,Dense, Flatten, Dropout, Conv2D, AveragePooling2D, MaxPool2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.datasets.mnist as mnist\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba9d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "model.add(MaxPool2D(strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc94603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 48)        38448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               307456    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                21588     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 369,174\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3093cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7564d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'D:\\\\ProcessedTrainingData'\n",
    "test_dir = 'D:\\\\ProcessedTestingData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2d152c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    training_data = []\n",
    "    training_data_Y = []\n",
    "    for j in tqdm(os.listdir(train_dir)):\n",
    "        for img in tqdm(os.listdir(os.path.join(train_dir,j))):\n",
    "            path = os.path.join(os.path.join(train_dir,j),img)\n",
    "            img_arr = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (28,28))\n",
    "            training_data.append(np.array(img_arr))\n",
    "            training_data_Y.append(img[0])\n",
    "    return training_data, training_data_Y\n",
    "def create_testing_data():\n",
    "    testing_data = []\n",
    "    testing_data_Y = []\n",
    "    for j in tqdm(os.listdir(test_dir)):\n",
    "        for img in tqdm(os.listdir(os.path.join(test_dir,j))):\n",
    "            path = os.path.join(os.path.join(test_dir,j),img)\n",
    "            img_arr = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (28,28))\n",
    "            testing_data.append(np.array(img_arr))\n",
    "            testing_data_Y.append(img[0])\n",
    "    return testing_data, testing_data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62feea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raining_data_X, training_data_Y = create_training_data()[0],create_training_data()[1]\n",
    "training_data_X = np.array(training_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e6f909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_X, testing_data_Y = create_testing_data()[0],create_testing_data()[1]\n",
    "testing_data_X = np.array(testing_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb4f7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the new training X values by stacking the two data sets\n",
    "X_train = np.vstack([X_train,X_train,training_data_X])\n",
    "X_test = np.vstack([X_test,X_test,testing_data_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0e4ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the new training X values by stacking the two data sets\n",
    "y_train = np.array(np.hstack([y_train,y_train,training_data_Y]),dtype=int)\n",
    "y_test =  np.array(np.hstack([y_test,y_test,testing_data_Y]),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4781a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "training_idx = sample(range(0,len(X_train)),len(X_train))\n",
    "testing_idx = sample(range(0,len(X_test)),len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "542b7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[training_idx]\n",
    "X_test = X_test[testing_idx]\n",
    "y_train = y_train[training_idx]\n",
    "y_test = y_test[testing_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e83d3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lines():\n",
    "    from random import randint,sample\n",
    "    pix = 28\n",
    "    arr = np.zeros([pix,pix],dtype='int32')\n",
    "    num_edges = randint(0,4)\n",
    "    which_edges = sample(range(0,4),num_edges)\n",
    "    for i in which_edges:\n",
    "        if i == 1:\n",
    "            arr[:,0:2] = 255\n",
    "        elif i ==2:\n",
    "            arr[0:2,:] = 255\n",
    "        elif i == 3:\n",
    "            arr[:,-2:] = 255\n",
    "        else:\n",
    "            arr[-2:,:] = 255\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e907007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_28_28_gen():\n",
    "    from random import sample\n",
    "    pix = 28\n",
    "    arr = np.zeros(pix**2,dtype='int32')\n",
    "    proportion = np.random.uniform(0,0.1)\n",
    "    num = int(np.floor(pix**2*proportion))\n",
    "    rands = list(set(sample(range(0,pix**2),num)))\n",
    "    arr[rands] = 255\n",
    "    arr = arr.reshape(pix,pix)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ceb4ac96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2cd17453b80>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(blank_28_28_gen(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b8c4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_idx = np.where(y_train == 0)[0]\n",
    "y_test_idx = np.where(y_test == 0 )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1464f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y_train_idx:\n",
    "    X_train[i] = blank_28_28_gen()\n",
    "for i in y_test_idx:\n",
    "    X_test[i] = blank_28_28_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb825e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(0,len(X_train)):\n",
    "    X_train[i] = X_train[i]+add_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a44303ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for i in range(0,len(X_test)):\n",
    "    X_test[i] = X_test[i]+add_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a29d7128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180272, 30000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03f9b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to edit our data to make it more suitable for Sudoku\n",
    "# In Sudoku there are only digits from 1-9, 0 = blank\n",
    "# So, we need to replace all 0s in the training and testing data with blank 28 x 28 with maybe\n",
    "# some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acc2282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8625be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_set_Y = to_categorical(y_train)\n",
    "new_testing_set_Y = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "059d50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64fb5579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is running\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90183610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Callbacks\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2459239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5634/5634 [==============================] - 34s 6ms/step - loss: 0.1230 - accuracy: 0.9735 - val_loss: 0.0705 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98170, saving model to weights-improvement-01-0.98.hdf5\n",
      "Epoch 2/10\n",
      "5634/5634 [==============================] - 33s 6ms/step - loss: 0.0401 - accuracy: 0.9891 - val_loss: 0.0278 - val_accuracy: 0.9927\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.98170 to 0.99270, saving model to weights-improvement-02-0.99.hdf5\n",
      "Epoch 3/10\n",
      "5634/5634 [==============================] - 33s 6ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.0490 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.99270\n",
      "Epoch 4/10\n",
      "5634/5634 [==============================] - 32s 6ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 0.0540 - val_accuracy: 0.9891\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.99270\n",
      "Epoch 5/10\n",
      "5634/5634 [==============================] - 30s 5ms/step - loss: 0.0226 - accuracy: 0.9945 - val_loss: 0.0396 - val_accuracy: 0.9922\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.99270\n",
      "Epoch 6/10\n",
      "5634/5634 [==============================] - 32s 6ms/step - loss: 0.0223 - accuracy: 0.9951 - val_loss: 0.0516 - val_accuracy: 0.9923\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99270\n",
      "Epoch 7/10\n",
      "5634/5634 [==============================] - 33s 6ms/step - loss: 0.0188 - accuracy: 0.9958 - val_loss: 0.0585 - val_accuracy: 0.9932\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.99270 to 0.99323, saving model to weights-improvement-07-0.99.hdf5\n",
      "Epoch 8/10\n",
      "5634/5634 [==============================] - 33s 6ms/step - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.0694 - val_accuracy: 0.9896\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99323\n",
      "Epoch 9/10\n",
      "5634/5634 [==============================] - 33s 6ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 0.0715 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99323\n",
      "Epoch 10/10\n",
      "5634/5634 [==============================] - 34s 6ms/step - loss: 0.0211 - accuracy: 0.9964 - val_loss: 0.0715 - val_accuracy: 0.9901\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cd261a27c0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See if it learns\n",
    "model.fit(X_train,new_training_set_Y, epochs=10, validation_data=(X_test,new_testing_set_Y),callbacks=[callbacks_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8f8d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model with the least val acc\n",
    "from keras.models import load_model\n",
    "\n",
    "model_trained = load_model('weights-improvement-02-0.99.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2769b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0365 - accuracy: 0.9910: 0s - loss:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03654364123940468, 0.9909999966621399]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate again\n",
    "model_trained.evaluate(X_test,new_testing_set_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75680168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
